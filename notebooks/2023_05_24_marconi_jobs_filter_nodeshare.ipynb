{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter 3: Filtering Marconi100 jobs that share a node"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data (output of `2023_05_22_marconi_jobs.ipynb`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24260/4178677611.py:3: DtypeWarning: Columns (62,88) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_jobs_single = pd.read_csv(\"../Marconi-test/plugin=job_table/metric=job_info_marconi100/a_0_f12_singlenode.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_jobs_single = pd.read_csv(\"../Marconi-test/plugin=job_table/metric=job_info_marconi100/a_0_f12_singlenode.csv\")\n",
    "df_jobs_multi = pd.read_csv(\"../Marconi-test/plugin=job_table/metric=job_info_marconi100/a_0_f12_multinode.csv\")\n",
    "\n",
    "#print(df_jobs_multi.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['timestamp', 'value', 'node'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_total_power = pd.read_parquet(\"../Marconi-test/plugin=ipmi_pub/metric=total_power/a_0.parquet\")\n",
    "df_total_power['node'] = pd.to_numeric(df_total_power['node'])\n",
    "df_total_power['value'] = pd.to_numeric(df_total_power['value'])\n",
    "print(df_total_power.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering for single node jobs\n",
    "\n",
    "The idea is to add a new column to `df_total_power` with a list of jobs that run on each node at each timestamp. Then we filter jobs that appear sharing with another job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    timestamp  value  node                  job_ids\n",
      "9102652   2022-05-09 22:00:00    820   616                  5217003\n",
      "9102653   2022-05-09 22:00:20    900   616                  5217003\n",
      "9102654   2022-05-09 22:00:40    880   616                  5217003\n",
      "9102655   2022-05-09 22:01:00    780   616                  5217003\n",
      "9102656   2022-05-09 22:01:20    680   616                  5217003\n",
      "...                       ...    ...   ...                      ...\n",
      "129200697 2022-05-28 21:58:20   1060   910  2891088,1851572,2540764\n",
      "129200698 2022-05-28 21:58:40   1120   910  2891088,1851572,2540764\n",
      "129200699 2022-05-28 21:59:00   1160   910  2891088,1851572,2540764\n",
      "129200700 2022-05-28 21:59:20   1200   910  2891088,1851572,2540764\n",
      "129200701 2022-05-28 21:59:40   1140   910  2891088,1851572,2540764\n",
      "\n",
      "[9249948 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "#df_jobs_f1_single = df_jobs_f1[df_jobs_f1[\"num_nodes\"]==1]\n",
    "\n",
    "#removing malformed \"nodes\"\n",
    "#df_jobs_f1_single = df_jobs_f1_single[df_jobs_f1_single[\"nodes\"].str.match(\"\\[\\d+\\]\")].copy().reset_index(drop=True)\n",
    "df_jobs_single[\"node\"] = [ast.literal_eval(x)[0] for x in df_jobs_single['nodes']]\n",
    "\n",
    "\n",
    "#use this for smaller inputs\n",
    "TEST_SAMPLE_SIZE = 20000\n",
    "sample = df_jobs_single[0:TEST_SAMPLE_SIZE].copy().reset_index(drop=True)\n",
    "\n",
    "#sample = df_jobs_single\n",
    "\n",
    "#df_total_power['job_ids'] = \"\"\n",
    "group = df_total_power.groupby(by=\"node\")\n",
    "\n",
    "#for debugging\n",
    "#result = [group.get_group(x[0])[\"timestamp\"].between(x[1], x[2]).value_counts() for x in sample[[\"node\", \"start_time\", \"end_time\"]].values.tolist()]\n",
    "\n",
    "#i know that x[0] is node, x[1] is start_time, and x[2] is end_time\n",
    "#each element of the list is a subseries of the total_power of a certain mode\n",
    "#with \"1\" at the timestamps where the \"job_id\" ran\n",
    "result = [[group.get_group(x[0])[\"timestamp\"].between(x[1], x[2]).astype(int).replace(0, np.nan).dropna().astype(str), x[3]] for x in sample[[\"node\", \"start_time\", \"end_time\", \"job_id\"]].values.tolist()]\n",
    "#print(result)\n",
    "\n",
    "\n",
    "if True:\n",
    "    #print(type(group.get_group(512)))\n",
    "    #group.get_group(x[0])\n",
    "\n",
    "    #result[0] = Series with timestamps with True where the job run, and False otherwise\n",
    "    #result[1] = job id\n",
    "    #result.values.to_list()\n",
    "\n",
    "    # now i replace the \"1\"s with the \"job_id\"\n",
    "    #each element of the list is a subseries of the total_power of a certain mode\n",
    "    #with the \"job_id\" value at the timestamps where the \"job_id\" ran\n",
    "    result2 = [x[0].replace(\"1.0\", str(x[1])) for x in result]\n",
    "    #print(result2)\n",
    "\n",
    "    #finally i concatenate each of the series by index\n",
    "    # while joining the values where indices overlap\n",
    "    # i hope the indices here are consistent with the indices in df_total_power \n",
    "    #concatenated_series = pd.concat(result2).groupby(level=0).apply(','.join).replace(to_replace=r'^(0,)*0$', value=\"0\", regex=True)\n",
    "    concatenated_series = pd.concat(result2).groupby(level=0).apply(','.join).rename(\"job_ids\")\n",
    "    #print(concatenated_series)\n",
    "\n",
    "    # use the below code for the full run\n",
    "    #joined_total_power = df_total_power.merge(concatenated_series, left_index=True, right_index=True, how=\"left\")\n",
    "\n",
    "    #use the below code for a rest run\n",
    "    joined_total_power = df_total_power.merge(concatenated_series, left_index=True, right_index=True, how=\"inner\")\n",
    "    print(joined_total_power)\n",
    "\n",
    "    #result3 = pd.concat(result2, verify_integrity=True)\n",
    "    #print(result3[result3.values != 0])\n",
    "\n",
    "    #sample[\"has_profile\"] = result\n",
    "    #df_jobs_f123_single = sample[sample[\"has_profile\"]==True]\n",
    "\n",
    "    #perc_jobs_filtered = (len(df_jobs_f123_single)/len(df_jobs_single))*100\n",
    "    #print(str(perc_jobs_filtered), \"% of the original job table\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joined_total_power.to_csv(\"../Marconi-test/plugin=ipmi_pub/metric=total_power/power_jobids_test.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the shared job ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodeshare Job ratio:  0.4406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        5217003\n",
       "9        3861114\n",
       "10       3435667\n",
       "11       6191535\n",
       "12       4796760\n",
       "          ...   \n",
       "36834     920827\n",
       "37131    5378422\n",
       "37132    3264690\n",
       "37135    3215425\n",
       "37143    5427250\n",
       "Length: 11188, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#job_ids = pd.Series([[int(y) for y in x.split(\",\")] for x in joined_total_power[\"job_ids\"].drop_duplicates().values.tolist()])\n",
    "\n",
    "all_job_ids=[]\n",
    "_ = pd.Series([[all_job_ids.append(y) for y in x.split(\",\")] for x in joined_total_power[\"job_ids\"].drop_duplicates().values.tolist()])\n",
    "\n",
    "all_job_ids = pd.Series(all_job_ids).drop_duplicates()\n",
    "\n",
    "nodeshare_job_ids = []\n",
    "_ = pd.Series([[nodeshare_job_ids.append(y) for y in x.split(\",\") if len(x.split(\",\")) > 1] for x in joined_total_power[\"job_ids\"].drop_duplicates().values.tolist()])\n",
    "nodeshare_job_ids = pd.Series(nodeshare_job_ids).drop_duplicates()\n",
    "\n",
    "exclusive_job_ids = all_job_ids[~all_job_ids.isin(nodeshare_job_ids)]\n",
    "\n",
    "print(\"Nodeshare Job ratio: \", len(nodeshare_job_ids)/len(all_job_ids))\n",
    "exclusive_job_ids\n",
    "#all_job_ids"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the profile of the not nodeshared jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x[0] = timestamp, x[1] = value (total_power), x[2] = node, x[3] = job_ids\n",
    "\n",
    "result = [x for x in joined_total_power.values if np.any(pd.Series(x[3].split(\",\")).isin(exclusive_job_ids).values) == True]\n",
    "\n",
    "df_result = pd.DataFrame(result, columns=[\"timestamp\", \"value\", \"node\", \"job_id\"])\n",
    "\n",
    "\n",
    "#result\n",
    "#joined_total_power.values\n",
    "#joined_total_power.values[0,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accrue_time</th>\n",
       "      <th>alloc_node</th>\n",
       "      <th>alloc_sid</th>\n",
       "      <th>array_job_id</th>\n",
       "      <th>array_max_tasks</th>\n",
       "      <th>array_task_id</th>\n",
       "      <th>array_task_str</th>\n",
       "      <th>array_task_throttle</th>\n",
       "      <th>assoc_id</th>\n",
       "      <th>batch_flag</th>\n",
       "      <th>...</th>\n",
       "      <th>tres_per_job</th>\n",
       "      <th>tres_per_node</th>\n",
       "      <th>tres_per_socket</th>\n",
       "      <th>tres_per_task</th>\n",
       "      <th>tres_req_str</th>\n",
       "      <th>user_id</th>\n",
       "      <th>wait4switch</th>\n",
       "      <th>wckey</th>\n",
       "      <th>node</th>\n",
       "      <th>has_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3231593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>464.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gres:gpu:1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>458</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3915009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gres:gpu:4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>291</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1492464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gres:gpu:4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>677</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6098620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gres:gpu:4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>363</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5198558</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gres:gpu:4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>694</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19993</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4687208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gres:gpu:0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>688</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2119760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gres:gpu:4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>441</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5661358</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gres:gpu:4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>962</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2586253</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gres:gpu:1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>367</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5731306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gres:gpu:4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>786</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11188 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       accrue_time  alloc_node  alloc_sid  array_job_id  array_max_tasks   \n",
       "0              NaN         NaN        NaN       3231593              NaN  \\\n",
       "2              NaN         NaN        NaN       3915009              NaN   \n",
       "7              NaN         NaN        NaN       1492464              NaN   \n",
       "15             NaN         NaN        NaN       6098620              NaN   \n",
       "24             NaN         NaN        NaN       5198558              NaN   \n",
       "...            ...         ...        ...           ...              ...   \n",
       "19993          NaN         NaN        NaN       4687208              NaN   \n",
       "19994          NaN         NaN        NaN       2119760              NaN   \n",
       "19996          NaN         NaN        NaN       5661358              NaN   \n",
       "19997          NaN         NaN        NaN       2586253              NaN   \n",
       "19999          NaN         NaN        NaN       5731306              NaN   \n",
       "\n",
       "       array_task_id  array_task_str  array_task_throttle  assoc_id   \n",
       "0              464.0             NaN                  NaN       NaN  \\\n",
       "2                NaN             NaN                  NaN       NaN   \n",
       "7                NaN             NaN                  NaN       NaN   \n",
       "15               NaN             NaN                  NaN       NaN   \n",
       "24               NaN             NaN                  NaN       NaN   \n",
       "...              ...             ...                  ...       ...   \n",
       "19993            NaN             NaN                  NaN       NaN   \n",
       "19994            NaN             NaN                  NaN       NaN   \n",
       "19996            NaN             NaN                  NaN       NaN   \n",
       "19997            NaN             NaN                  NaN       NaN   \n",
       "19999            NaN             NaN                  NaN       NaN   \n",
       "\n",
       "       batch_flag  ...  tres_per_job  tres_per_node  tres_per_socket   \n",
       "0             NaN  ...           NaN     gres:gpu:1              NaN  \\\n",
       "2             NaN  ...           NaN     gres:gpu:4              NaN   \n",
       "7             NaN  ...           NaN     gres:gpu:4              NaN   \n",
       "15            NaN  ...           NaN     gres:gpu:4              NaN   \n",
       "24            NaN  ...           NaN     gres:gpu:4              NaN   \n",
       "...           ...  ...           ...            ...              ...   \n",
       "19993         NaN  ...           NaN     gres:gpu:0              NaN   \n",
       "19994         NaN  ...           NaN     gres:gpu:4              NaN   \n",
       "19996         NaN  ...           NaN     gres:gpu:4              NaN   \n",
       "19997         NaN  ...           NaN     gres:gpu:1              NaN   \n",
       "19999         NaN  ...           NaN     gres:gpu:4              NaN   \n",
       "\n",
       "       tres_per_task  tres_req_str  user_id wait4switch  wckey  node   \n",
       "0                NaN           NaN     1234         NaN    NaN   458  \\\n",
       "2                NaN           NaN     1188         NaN    NaN   291   \n",
       "7                NaN           NaN     1702         NaN    NaN   677   \n",
       "15               NaN           NaN     1702         NaN    NaN   363   \n",
       "24               NaN           NaN     1702         NaN    NaN   694   \n",
       "...              ...           ...      ...         ...    ...   ...   \n",
       "19993            NaN           NaN     1167         NaN    NaN   688   \n",
       "19994            NaN           NaN      161         NaN    NaN   441   \n",
       "19996            NaN           NaN      161         NaN    NaN   962   \n",
       "19997            NaN           NaN      112         NaN    NaN   367   \n",
       "19999            NaN           NaN      161         NaN    NaN   786   \n",
       "\n",
       "       has_profile  \n",
       "0             True  \n",
       "2             True  \n",
       "7             True  \n",
       "15            True  \n",
       "24            True  \n",
       "...            ...  \n",
       "19993         True  \n",
       "19994         True  \n",
       "19996         True  \n",
       "19997         True  \n",
       "19999         True  \n",
       "\n",
       "[11188 rows x 91 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exclusive_jobs = df_jobs_single[df_jobs_single[\"job_id\"].isin(exclusive_job_ids.astype(int))]\n",
    "df_exclusive_jobs\n",
    "#exclusive_job_ids\n",
    "#df_jobs_single = pd.read_csv(\"../Marconi-test/plugin=job_table/metric=job_info_marconi100/a_0_f12_singlenode.csv\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv(\"../Marconi-test/plugin=ipmi_pub/metric=total_power/power_jobids_test_exclusive.csv\", index=False)\n",
    "df_exclusive_jobs.to_csv(\"../Marconi-test/plugin=job_table/metric=job_info_marconi100/a_0_f12_singlenode_test_exclusive.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering for multinode jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    timestamp  value  node  job_ids\n",
      "18342767  2022-05-19 22:00:00    980   137   717969\n",
      "18342768  2022-05-19 22:00:20    980   137   717969\n",
      "18342769  2022-05-19 22:00:40   1000   137   717969\n",
      "18342770  2022-05-19 22:01:00   1000   137   717969\n",
      "18342771  2022-05-19 22:01:20   1020   137   717969\n",
      "...                       ...    ...   ...      ...\n",
      "129200199 2022-05-28 19:12:20    580   910  4254976\n",
      "129200200 2022-05-28 19:12:40   1220   910  4254976\n",
      "129200201 2022-05-28 19:13:00    820   910  4254976\n",
      "129200202 2022-05-28 19:13:20    520   910  4254976\n",
      "129200203 2022-05-28 19:13:40    420   910  4254976\n",
      "\n",
      "[5082058 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "#df_jobs_f1_single = df_jobs_f1[df_jobs_f1[\"num_nodes\"]==1]\n",
    "\n",
    "#removing malformed \"nodes\"\n",
    "#df_jobs_f1_single = df_jobs_f1_single[df_jobs_f1_single[\"nodes\"].str.match(\"\\[\\d+\\]\")].copy().reset_index(drop=True)\n",
    "df_jobs_multi[\"node\"] = [ast.literal_eval(x) for x in df_jobs_multi['nodes']]\n",
    "\n",
    "#print(df_jobs_multi[\"node\"])\n",
    "\n",
    "if True:\n",
    "\n",
    "\n",
    "    #use this for smaller inputs\n",
    "    TEST_SAMPLE_SIZE = 1000\n",
    "    sample = df_jobs_multi[0:TEST_SAMPLE_SIZE].copy().reset_index(drop=True)\n",
    "\n",
    "    #sample = df_jobs_single\n",
    "\n",
    "    #df_total_power['job_ids'] = \"\"\n",
    "    group = df_total_power.groupby(by=\"node\")\n",
    "\n",
    "    #for debugging\n",
    "    #result = [group.get_group(x[0])[\"timestamp\"].between(x[1], x[2]).value_counts() for x in sample[[\"node\", \"start_time\", \"end_time\"]].values.tolist()]\n",
    "\n",
    "    #i know that x[0] is the node list, x[1] is start_time, and x[2] is end_time\n",
    "    #each element of the list is a subseries of the total_power of a certain mode\n",
    "    #with \"1\" at the timestamps where the \"job_id\" ran\n",
    "    # i replace the \"0\"s (where the timestamp is not betweenx[1], x[2]) with nans just to remove these values with dropna.\n",
    "    result = [[[group.get_group(y)[\"timestamp\"].between(x[1], x[2]).astype(int).replace(0, np.nan).dropna().astype(str) for y in x[0]], x[3]] for x in sample[[\"node\", \"start_time\", \"end_time\", \"job_id\"]].values.tolist()]\n",
    "   \n",
    "    #result = [[group.get_group(x[0])[\"timestamp\"].between(x[1], x[2]).astype(int).replace(0, np.nan).dropna().astype(str), x[3]] for x in sample[[\"node\", \"start_time\", \"end_time\", \"job_id\"]].values.tolist()]\n",
    "    #print(result)\n",
    "\n",
    "\n",
    "    if True:\n",
    "        #print(type(group.get_group(512)))\n",
    "        #group.get_group(x[0])\n",
    "\n",
    "        #result[0] = Series with timestamps with True where the job run, and False otherwise\n",
    "        #result[1] = job id\n",
    "        #result.values.to_list()\n",
    "\n",
    "        # now i replace the \"1\"s with the \"job_id\"\n",
    "        #each element of the list is a subseries of the total_power of a certain mode\n",
    "        #with the \"job_id\" value at the timestamps where the \"job_id\" ran\n",
    "        result2 = [pd.concat([y.replace(\"1.0\", str(x[1])) for y in x[0]]) for x in result]\n",
    "\n",
    "        #result2 = [x[0].replace(\"1.0\", str(x[1])) for x in result]\n",
    "        #print(result2)\n",
    "        if True:\n",
    "            #finally i concatenate each of the series by index\n",
    "            # while joining the values where indices overlap\n",
    "            # i hope the indices here are consistent with the indices in df_total_power \n",
    "            #concatenated_series = pd.concat(result2).groupby(level=0).apply(','.join).replace(to_replace=r'^(0,)*0$', value=\"0\", regex=True)\n",
    "                        \n",
    "            concatenated_series = pd.concat(result2).groupby(level=0).apply(','.join).rename(\"job_ids\")\n",
    "            #print(concatenated_series)\n",
    "\n",
    "            # use the below code for the full run\n",
    "            #joined_total_power = df_total_power.merge(concatenated_series, left_index=True, right_index=True, how=\"left\")\n",
    "\n",
    "            #use the below code for a rest run\n",
    "            joined_total_power = df_total_power.merge(concatenated_series, left_index=True, right_index=True, how=\"inner\")\n",
    "            print(joined_total_power)\n",
    "\n",
    "            #result3 = pd.concat(result2, verify_integrity=True)\n",
    "            #print(result3[result3.values != 0])\n",
    "\n",
    "            #sample[\"has_profile\"] = result\n",
    "            #df_jobs_f123_single = sample[sample[\"has_profile\"]==True]\n",
    "\n",
    "            #perc_jobs_filtered = (len(df_jobs_f123_single)/len(df_jobs_single))*100\n",
    "            #print(str(perc_jobs_filtered), \"% of the original job table\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the shared job IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodeshare Job ratio:  0.018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        717969\n",
       "1       2142977\n",
       "2       2572647\n",
       "3       1906617\n",
       "4       3865315\n",
       "         ...   \n",
       "1020    5290204\n",
       "1021    4727631\n",
       "1022     207237\n",
       "1023    3724077\n",
       "1024     595230\n",
       "Length: 982, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#job_ids = pd.Series([[int(y) for y in x.split(\",\")] for x in joined_total_power[\"job_ids\"].drop_duplicates().values.tolist()])\n",
    "\n",
    "all_job_ids=[]\n",
    "_ = pd.Series([[all_job_ids.append(y) for y in x.split(\",\")] for x in joined_total_power[\"job_ids\"].drop_duplicates().values.tolist()])\n",
    "\n",
    "all_job_ids = pd.Series(all_job_ids).drop_duplicates()\n",
    "\n",
    "nodeshare_job_ids = []\n",
    "_ = pd.Series([[nodeshare_job_ids.append(y) for y in x.split(\",\") if len(x.split(\",\")) > 1] for x in joined_total_power[\"job_ids\"].drop_duplicates().values.tolist()])\n",
    "nodeshare_job_ids = pd.Series(nodeshare_job_ids).drop_duplicates()\n",
    "\n",
    "exclusive_job_ids = all_job_ids[~all_job_ids.isin(nodeshare_job_ids)]\n",
    "\n",
    "print(\"Nodeshare Job ratio: \", len(nodeshare_job_ids)/len(all_job_ids))\n",
    "exclusive_job_ids\n",
    "#all_job_ids"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the profile of not nodeshared jobs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x[0] = timestamp, x[1] = value (total_power), x[2] = node, x[3] = job_ids\n",
    "\n",
    "result = [x for x in joined_total_power.values if np.any(pd.Series(x[3].split(\",\")).isin(exclusive_job_ids).values) == True]\n",
    "\n",
    "df_result = pd.DataFrame(result, columns=[\"timestamp\", \"value\", \"node\", \"job_id\"])\n",
    "\n",
    "\n",
    "#result\n",
    "#joined_total_power.values\n",
    "#joined_total_power.values[0,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accrue_time</th>\n",
       "      <th>alloc_node</th>\n",
       "      <th>alloc_sid</th>\n",
       "      <th>array_job_id</th>\n",
       "      <th>array_max_tasks</th>\n",
       "      <th>array_task_id</th>\n",
       "      <th>array_task_str</th>\n",
       "      <th>array_task_throttle</th>\n",
       "      <th>assoc_id</th>\n",
       "      <th>batch_flag</th>\n",
       "      <th>...</th>\n",
       "      <th>tres_per_job</th>\n",
       "      <th>tres_per_node</th>\n",
       "      <th>tres_per_socket</th>\n",
       "      <th>tres_per_task</th>\n",
       "      <th>tres_req_str</th>\n",
       "      <th>user_id</th>\n",
       "      <th>wait4switch</th>\n",
       "      <th>wckey</th>\n",
       "      <th>node</th>\n",
       "      <th>has_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2238969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gres:gpu:4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[115, 150, 708, 710]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2086453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gres:gpu:4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[464, 465, 466, 491, 492, 493, 509, 510, 512, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1803092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gres:gpu:4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[540, 541, 543, 544, 546, 547, 548, 551, 552, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>956733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gres:gpu:4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[238, 773, 831, 924]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3032910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gres:gpu:4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[531, 532, 533, 535, 537, 538]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3176171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gres:gpu:4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[36, 78, 237, 692]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3469816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gres:gpu:4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[460, 461, 480, 481, 482, 503, 509, 511, 520, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2622845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gres:gpu:4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[40, 80, 161, 201, 240, 280, 360, 401, 441, 60...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2029327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gres:gpu:4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[361, 405]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6029546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gres:gpu:4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[464, 471, 485, 486, 489, 515, 517, 518, 522, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>982 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     accrue_time  alloc_node  alloc_sid  array_job_id  array_max_tasks   \n",
       "0            NaN         NaN        NaN       2238969              NaN  \\\n",
       "1            NaN         NaN        NaN       2086453              NaN   \n",
       "2            NaN         NaN        NaN       1803092              NaN   \n",
       "3            NaN         NaN        NaN        956733              NaN   \n",
       "4            NaN         NaN        NaN       3032910              NaN   \n",
       "..           ...         ...        ...           ...              ...   \n",
       "995          NaN         NaN        NaN       3176171              NaN   \n",
       "996          NaN         NaN        NaN       3469816              NaN   \n",
       "997          NaN         NaN        NaN       2622845              NaN   \n",
       "998          NaN         NaN        NaN       2029327              NaN   \n",
       "999          NaN         NaN        NaN       6029546              NaN   \n",
       "\n",
       "     array_task_id  array_task_str  array_task_throttle  assoc_id  batch_flag   \n",
       "0              NaN             NaN                  NaN       NaN         NaN  \\\n",
       "1              NaN             NaN                  NaN       NaN         NaN   \n",
       "2              NaN             NaN                  NaN       NaN         NaN   \n",
       "3              NaN             NaN                  NaN       NaN         NaN   \n",
       "4              2.0             NaN                  NaN       NaN         NaN   \n",
       "..             ...             ...                  ...       ...         ...   \n",
       "995            NaN             NaN                  NaN       NaN         NaN   \n",
       "996            NaN             NaN                  NaN       NaN         NaN   \n",
       "997            NaN             NaN                  NaN       NaN         NaN   \n",
       "998            NaN             NaN                  NaN       NaN         NaN   \n",
       "999            NaN             NaN                  NaN       NaN         NaN   \n",
       "\n",
       "     ...  tres_per_job  tres_per_node  tres_per_socket  tres_per_task   \n",
       "0    ...           NaN     gres:gpu:4              NaN            NaN  \\\n",
       "1    ...           NaN     gres:gpu:4              NaN            NaN   \n",
       "2    ...           NaN     gres:gpu:4              NaN            NaN   \n",
       "3    ...           NaN     gres:gpu:4              NaN            NaN   \n",
       "4    ...           NaN     gres:gpu:4              NaN            NaN   \n",
       "..   ...           ...            ...              ...            ...   \n",
       "995  ...           NaN     gres:gpu:4              NaN            NaN   \n",
       "996  ...           NaN     gres:gpu:4              NaN            NaN   \n",
       "997  ...           NaN     gres:gpu:4              NaN            NaN   \n",
       "998  ...           NaN     gres:gpu:4              NaN            NaN   \n",
       "999  ...           NaN     gres:gpu:4              NaN            NaN   \n",
       "\n",
       "     tres_req_str  user_id wait4switch  wckey   \n",
       "0             NaN     1381         NaN    NaN  \\\n",
       "1             NaN     1380         NaN    NaN   \n",
       "2             NaN      696         NaN    NaN   \n",
       "3             NaN      609         NaN    NaN   \n",
       "4             NaN      640         NaN    NaN   \n",
       "..            ...      ...         ...    ...   \n",
       "995           NaN     1430         NaN    NaN   \n",
       "996           NaN     1380         NaN    NaN   \n",
       "997           NaN      826         NaN    NaN   \n",
       "998           NaN      150         NaN    NaN   \n",
       "999           NaN     1380         NaN    NaN   \n",
       "\n",
       "                                                  node  has_profile  \n",
       "0                                 [115, 150, 708, 710]         True  \n",
       "1    [464, 465, 466, 491, 492, 493, 509, 510, 512, ...         True  \n",
       "2    [540, 541, 543, 544, 546, 547, 548, 551, 552, ...         True  \n",
       "3                                 [238, 773, 831, 924]         True  \n",
       "4                       [531, 532, 533, 535, 537, 538]         True  \n",
       "..                                                 ...          ...  \n",
       "995                                 [36, 78, 237, 692]         True  \n",
       "996  [460, 461, 480, 481, 482, 503, 509, 511, 520, ...         True  \n",
       "997  [40, 80, 161, 201, 240, 280, 360, 401, 441, 60...         True  \n",
       "998                                         [361, 405]         True  \n",
       "999  [464, 471, 485, 486, 489, 515, 517, 518, 522, ...         True  \n",
       "\n",
       "[982 rows x 91 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exclusive_jobs = df_jobs_multi[df_jobs_multi[\"job_id\"].isin(exclusive_job_ids.astype(int))]\n",
    "df_exclusive_jobs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv(\"../Marconi-test/plugin=ipmi_pub/metric=total_power/power_jobids_test_exclusive_multinode.csv\", index=False)\n",
    "df_exclusive_jobs.to_csv(\"../Marconi-test/plugin=job_table/metric=job_info_marconi100/a_0_f12_singlenode_test_exclusive_multinode.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting exclusive single node jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_jobs_viz = pd.read_csv(\"../Marconi-test/plugin=job_table/metric=job_info_marconi100/a_0_f12_singlenode_test_exclusive.csv\")\n",
    "\n",
    "df_power = pd.read_csv(\"../Marconi-test/plugin=ipmi_pub/metric=total_power/power_jobids_test_exclusive.csv\")\n",
    "df_power['node'] = pd.to_numeric(df_power['node'])\n",
    "df_power['value'] = pd.to_numeric(df_power['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "912838d071644ef6a97de28edd189e5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Save to PDF', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec3c76d79744b0bac607b2275d1b417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1585cd847c04b2ca65c04ae968aef0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=11187), IntSlider(value=1, description='wind…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "\n",
    "#gfig = None\n",
    "\n",
    "def call_workflow(index, window_size):\n",
    "    get_job_energy_profile(index, window_size)\n",
    "\n",
    "def get_job_energy_profile(index, window_size):\n",
    "    global current_job_id, current_hostname\n",
    "    annot_str=''\n",
    "    job=df_jobs_viz.iloc[index,:]\n",
    "    nodes=ast.literal_eval(job['nodes'])\n",
    "    start_time=job[\"start_time\"]\n",
    "    end_time=job[\"end_time\"]\n",
    "    for node in nodes:\n",
    "        print(node)\n",
    "        df_node = df_power.loc[df_power['node'] == node]\n",
    "        df_node_job = df_node.loc[df_node['timestamp'].between(start_time, end_time)].sort_values(by=\"timestamp\").reset_index(drop=True)\n",
    "        df_node_job[\"rolling_mean\"] = df_node_job.sort_values(by=\"timestamp\").reset_index()[\"value\"].rolling(window=window_size, center=True).mean()\n",
    "        if len(df_node_job) > 0:\n",
    "            #print(df_node_job.describe(), end=\"\\r\")\n",
    "            plot_energy_profile(df_node_job, annot_str)\n",
    "    print(nodes)\n",
    "     \n",
    "    #plot_energy_profile(job_energy_profile, annot_str)\n",
    "\n",
    "    #current_job_id=str(job['job_id'])\n",
    "    #current_hostname=energy_host\n",
    "    ##\n",
    "    #describe=job_energy_profile.describe(percentiles=[.10, .25, .5, .75, .90])\n",
    "    #describe['job_id']=job['job_id']\n",
    "    #describe['socket']=socket\n",
    "    #describe['pp0']=describe[right_pp0]\n",
    "    #describe['DRAM']=describe[right_DRAM]\n",
    "    #describe['stat']=describe.index\n",
    "    #describe=describe.reset_index(drop=True)[arr_cols]  \n",
    "    #print(describe)  \n",
    "\n",
    "\n",
    "def plot_energy_profile(profile, annot_str):\n",
    "    TINY_SIZE = 2\n",
    "    SMALL_SIZE = 5\n",
    "    MEDIUM_SIZE = 25\n",
    "    BIGGER_SIZE = 50\n",
    "    FIG_WIDTH = 50\n",
    "    FIG_HEIGHT = 20\n",
    "\n",
    "    global gfig    \n",
    "\n",
    "    plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
    "    plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize=BIGGER_SIZE)     # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=BIGGER_SIZE)    # legend fontsize\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "    scatterplot_kwargs={'s': 50, 'palette': 'plasma'}\n",
    "    lineplot_kwargs={'linewidth': 5}\n",
    "\n",
    "    plt.clf()\n",
    "    fig = plt.figure(figsize=(FIG_WIDTH,FIG_HEIGHT))\n",
    "    #ax = sns.boxplot(x='stat', y='value', data=plot_data, showfliers=False, hue='reading',\n",
    "    #             linewidth=TINY_SIZE)\n",
    "\n",
    "        #print(profile_cpy[\"value\"])\n",
    "    ax = sns.scatterplot(data=profile, x='timestamp', y='rolling_mean', **scatterplot_kwargs)\n",
    "    #ax = sns.lineplot(data=profile, x='timestamp', y='value', **lineplot_kwargs)\n",
    "\n",
    "    ## SET BORDERS SIZE AND WIDTH\n",
    "    [line.set_linewidth(TINY_SIZE) for line in ax.spines.values()]\n",
    "    [line.set_markersize(TINY_SIZE) for line in ax.yaxis.get_ticklines()]\n",
    "    [line.set_markeredgewidth(TINY_SIZE) for line in ax.yaxis.get_ticklines()]\n",
    "    [line.set_markersize(SMALL_SIZE) for line in ax.xaxis.get_ticklines()]\n",
    "    [line.set_markeredgewidth(TINY_SIZE) for line in ax.xaxis.get_ticklines()]\n",
    "    #ax.text(x=0.1,y=0.5,\n",
    "    #        s=annot_str,\n",
    "    #        fontdict=dict(color='red',size=MEDIUM_SIZE),\n",
    "    #        bbox=dict(facecolor='yellow',alpha=0.5),\n",
    "    #        horizontalalignment='left',\n",
    "    #        verticalalignment='center',\n",
    "    #        transform=ax.transAxes)\n",
    "    ax.set_ylabel('Processor Power (Watts)')\n",
    "    ax.set_xlabel('Timestamp')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    gfig = fig\n",
    "\n",
    "button = widgets.Button(description=\"Save to PDF\")\n",
    "output = widgets.Output()\n",
    "\n",
    "display(button, output)\n",
    "\n",
    "## TODO: Pass on b the data (job_id, hostname, etc)\n",
    "def on_button_clicked(b):\n",
    "    with output:\n",
    "        #fig=plt.gcf()\n",
    "        #print(gfig)\n",
    "        fig_filename='../Figures/marconi100_interact_plot_'+current_hostname+'_'+current_job_id+'.pdf'\n",
    "        gfig.savefig(fig_filename, format='pdf', dpi=300, bbox_inches='tight')\n",
    "        print('Plot saved as '+fig_filename)\n",
    "\n",
    "button.on_click(on_button_clicked)\n",
    "\n",
    "interact(call_workflow, index=widgets.IntSlider(min=0, max=len(df_jobs_viz)-1, step=1, value=0),\n",
    "         window_size=widgets.IntSlider(min=1, max=30, step=1, value=1));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting exclusive multinode jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_jobs_viz = pd.read_csv(\"../Marconi-test/plugin=job_table/metric=job_info_marconi100/a_0_f12_singlenode_test_exclusive_multinode.csv\")\n",
    "\n",
    "df_power = pd.read_csv(\"../Marconi-test/plugin=ipmi_pub/metric=total_power/power_jobids_test_exclusive_multinode.csv\")\n",
    "df_power['node'] = pd.to_numeric(df_power['node'])\n",
    "df_power['value'] = pd.to_numeric(df_power['value'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
